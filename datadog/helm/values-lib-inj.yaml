nameOverride:  # ""
fullnameOverride:  # ""
targetSystem: "linux"
registry: gcr.io/datadoghq
datadog:
  apiKey: <DATADOG_API_KEY>
  apiKeyExistingSecret:  # <DATADOG_API_KEY_SECRET>
  appKey: # <DATADOG_APP_KEY>
  appKeyExistingSecret:  # <DATADOG_APP_KEY_SECRET>
  secretBackend:
    command:  # "/readsecret.sh" or "/readsecret_multiple_providers.sh" or any custom binary path
    arguments:  # "/etc/secret-volume" or any other custom arguments
    timeout:  # 30
    enableGlobalPermissions: true
    roles: []
  securityContext:
    runAsUser: 0
  hostVolumeMountPropagation: None
  clusterName: federator-ai-2 # <CLUSTER_NAME>
  site:  # datadoghq.com
  dd_url:  # https://app.datadoghq.com
  logLevel: DEBUG
  kubeStateMetricsEnabled: false
  kubeStateMetricsNetworkPolicy:
    create: false
  kubeStateMetricsCore:
    enabled: true
    ignoreLegacyKSMCheck: true
    collectSecretMetrics: true
    collectVpaMetrics: false
    useClusterCheckRunners: false
    labelsAsTags: {}
  clusterChecks:
    enabled: true
    shareProcessNamespace: false
  nodeLabelsAsTags: {}
  podLabelsAsTags: {}
  podAnnotationsAsTags: {}
  namespaceLabelsAsTags: {}
  tags: []
  checksCardinality:  # low, orchestrator or high (not set by default to avoid overriding existing DD_CHECKS_TAG_CARDINALITY configurations, the default value in the Agent is low)
  kubelet:
    host:
      valueFrom:
        fieldRef:
          fieldPath: status.hostIP
    tlsVerify: false # false
    hostCAPath:
    agentCAPath:
    podLogsPath:
  expvarPort: 6000
  dogstatsd:
    port: 8125
    originDetection: true
    tags: []
    tagCardinality: high
    useSocketVolume: true
    socketPath: /var/run/datadog/dsd.socket
    hostSocketPath: /var/run/datadog/
    useHostPort: true
    useHostPID: true
    nonLocalTraffic: true
  collectEvents: true
  leaderElection: true
  leaderLeaseDuration:  # 60
  logs:
    enabled: false
    containerCollectAll: false
    containerCollectUsingFiles: true
    autoMultiLineDetection: false
  apm:
    socketEnabled: true
    portEnabled: true
    enabled: true
    port: 8126
    useSocketVolume: false
    socketPath: /var/run/datadog/apm.socket
    hostSocketPath: /var/run/datadog/
  envFrom: []
  env: []
  confd:
    openmetrics.yaml: |-
      ad_identifiers:
        - cluster-agent-dev
      init_config:
      instances:
        - prometheus_url: http://%%host%%:5000/metrics
          namespace: "datadog.cluster_agent"
          metrics:
            - admission_webhooks_library_injection_attempts: admission_webhooks.library_injection_attempts
              admission_webhooks_mutation_attempts: admission_webhooks.mutation_attempts
              admission_webhooks_mutation_errors: admission_webhooks.mutation_errors
              admission_webhooks_response_duration: admission_webhooks.response_duration
              admission_webhooks_library_injection_errors: admission_webhooks.library_injection_errors
  checksd: {}
  dockerSocketPath:  # /var/run/docker.sock
  criSocketPath:  # /var/run/containerd/containerd.sock
  containerRuntimeSupport:
    enabled: true
  processAgent:
    enabled: false
    processCollection: false
    stripProcessArguments: false
    processDiscovery: false
  systemProbe:
    debugPort: 0
    enableConntrack: true
    seccomp: localhost/system-probe
    seccompRoot: /var/lib/kubelet/seccomp
    bpfDebug: false
    apparmor: unconfined
    enableTCPQueueLength: false
    enableOOMKill: false
    enableRuntimeCompiler: false
    enableKernelHeaderDownload: false
    mountPackageManagementDirs: []
    osReleasePath:
    runtimeCompilationAssetDir: /var/tmp/datadog-agent/system-probe
    collectDNSStats: true
    maxTrackedConnections: 131072
    conntrackMaxStateSize: 131072  # 2 * maxTrackedConnections by default, per  https://github.com/DataDog/datadog-agent/blob/d1c5de31e1bba72dfac459aed5ff9562c3fdcc20/pkg/process/config/config.go#L229
    conntrackInitTimeout: 10s
  orchestratorExplorer:
    enabled: true
    container_scrubbing:
      enabled: true
  helmCheck:
    enabled: false
    collectEvents: true
  networkMonitoring:
    enabled: false
  serviceMonitoring:
    enabled: true
  securityAgent:
    compliance:
      enabled: false
      configMap:
      checkInterval: 20m
    runtime:
      enabled: false
      fimEnabled: false
      policies:
        configMap:
      syscallMonitor:
        enabled: false
      network:
        enabled: false
  networkPolicy:
    create: false
    flavor: kubernetes
    cilium:
      dnsSelector:
        toEndpoints:
          - matchLabels:
              "k8s:io.kubernetes.pod.namespace": kube-system
              "k8s:k8s-app": kube-dns
  prometheusScrape:
    enabled: false
    serviceEndpoints: false
    additionalConfigs: []
    version: 2
  ignoreAutoConfig: []
  containerExclude:  # "image:datadog/agent"
  containerInclude:
  containerExcludeLogs:
  containerIncludeLogs:
  containerExcludeMetrics:
  containerIncludeMetrics:
  excludePauseContainer: true
clusterAgent:
  enabled: true
  shareProcessNamespace: false
  image:
    name: cluster-agent
    tag: rc
    repository:
    pullPolicy: Always
    pullSecrets: []
  securityContext: {}
  containers:
    clusterAgent:
      securityContext: {}
  command: []
  token: ""
  tokenExistingSecret: ""
  replicas: 1
  revisionHistoryLimit: 10
  rbac:
    create: true
    serviceAccountName: default
    serviceAccountAnnotations: {}
  podSecurity:
    podSecurityPolicy:
      create: false
    securityContextConstraints:
      create: false
  metricsProvider:
    enabled: false
    wpaController: false
    useDatadogMetrics: false
    createReaderRbac: true
    aggregator: avg
    service:
      type: ClusterIP
      port: 8443
    endpoint:  # https://api.datadoghq.com
  env: []
  envFrom: []
  admissionController:
    enabled: true
    mutateUnlabelled: true
    configMode: "socket" # "hostip", "socket" or "service"
    failurePolicy: Ignore
  confd: {}
  advancedConfd: {}
  resources: {}
  priorityClassName:  # system-cluster-critical
  nodeSelector: {}
  tolerations: []
  affinity: {}
  healthPort: 5556
  livenessProbe:
    initialDelaySeconds: 15
    periodSeconds: 15
    timeoutSeconds: 5
    successThreshold: 1
    failureThreshold: 6
  readinessProbe:
    initialDelaySeconds: 15
    periodSeconds: 15
    timeoutSeconds: 5
    successThreshold: 1
    failureThreshold: 6
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  deploymentAnnotations: {}
  podAnnotations: {}
  useHostNetwork: false
  dnsConfig: {}
  volumes: []
  volumeMounts: []
  datadog_cluster_yaml: {}
  createPodDisruptionBudget: false
  networkPolicy:
    create: false
  additionalLabels: {}
existingClusterAgent:
  join: false
  tokenSecretName:  # <EXISTING_DCA_SECRET_NAME>
  serviceName:  # <EXISTING_DCA_SERVICE_NAME>
  clusterchecksEnabled: true
agents:
  enabled: true
  shareProcessNamespace: false
  revisionHistoryLimit: 10
  image:
    name: "agent"
    tag: 7.39.0-rc.5
    tagSuffix: ""
    repository:
    doNotCheckTag: true # false
    pullPolicy: IfNotPresent
    pullSecrets: []
  rbac:
    create: true
    serviceAccountName: default
    serviceAccountAnnotations: {}
  podSecurity:
    podSecurityPolicy:
      create: false
    securityContextConstraints:
      create: false
    seLinuxContext:
      rule: MustRunAs
      seLinuxOptions:
        user: system_u
        role: system_r
        type: spc_t
        level: s0
    privileged: false
    capabilities:
      - SYS_ADMIN
      - SYS_RESOURCE
      - SYS_PTRACE
      - NET_ADMIN
      - NET_BROADCAST
      - NET_RAW
      - IPC_LOCK
      - CHOWN
      - AUDIT_CONTROL
      - AUDIT_READ
    allowedUnsafeSysctls: []
    volumes:
      - configMap
      - downwardAPI
      - emptyDir
      - hostPath
      - secret
    seccompProfiles:
      - "runtime/default"
      - "localhost/system-probe"
    apparmor:
      enabled: true
    apparmorProfiles:
      - "runtime/default"
      - "unconfined"
    defaultApparmor: runtime/default
  containers:
    agent:
      env:
      - name: GRPC_GO_LOG_VERBOSITY_LEVEL
        value: "99"
      - name: GRPC_GO_LOG_SEVERITY_LEVEL
        value: "info"
      envFrom: []
      logLevel:  # INFO
      resources: {}
      healthPort: 5555
      livenessProbe:
        initialDelaySeconds: 15
        periodSeconds: 15
        timeoutSeconds: 5
        successThreshold: 1
        failureThreshold: 6
      readinessProbe:
        initialDelaySeconds: 15
        periodSeconds: 15
        timeoutSeconds: 5
        successThreshold: 1
        failureThreshold: 6
      securityContext: {}
      ports: []
    processAgent:
      env: []
      envFrom: []
      logLevel:  # INFO
      resources: {}
      securityContext: {}
      ports: []
    traceAgent:
      env:
      - name: GRPC_GO_LOG_VERBOSITY_LEVEL
        value: "99"
      - name: GRPC_GO_LOG_SEVERITY_LEVEL
        value: "info"
      envFrom: []
      logLevel:  # INFO
      resources: {}
      livenessProbe:
        initialDelaySeconds: 15
        periodSeconds: 15
        timeoutSeconds: 5
      securityContext: {}
      ports: []
    systemProbe:
      env: []
      envFrom: []
      logLevel:  # INFO
      resources: {}
      securityContext:
        privileged: false
        capabilities:
          add: ["SYS_ADMIN", "SYS_RESOURCE", "SYS_PTRACE", "NET_ADMIN", "NET_BROADCAST", "NET_RAW", "IPC_LOCK", "CHOWN"]
      ports: []
    securityAgent:
      env:
      envFrom: []
      logLevel:  # INFO
      resources: {}
      ports: []
    initContainers:
      resources: {}
  volumes: []
  volumeMounts: []
  useHostNetwork: false
  dnsConfig: {}
  daemonsetAnnotations: {}
  podAnnotations: {}
  tolerations: []
  nodeSelector: {}
  affinity: {}
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: "10%"
  priorityClassCreate: false
  priorityClassName:
  priorityClassValue: 1000000000
  podLabels: {}
  additionalLabels: {}
  useConfigMap:  # false
  customAgentConfig: {}
  networkPolicy:
    create: false
  localService:
    overrideName: ""
    forceLocalServiceEnabled: false
clusterChecksRunner:
  enabled: false
  image:
    name: "agent"
    tag: latest
    tagSuffix: ""
    repository:
    pullPolicy: IfNotPresent
    pullSecrets: []
  createPodDisruptionBudget: false
  rbac:
    create: true
    dedicated: false
    serviceAccountAnnotations: {}
    serviceAccountName: default
  replicas: 1
  revisionHistoryLimit: 10
  resources: {}
  affinity: {}
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  dnsConfig: {}
  priorityClassName:  # system-cluster-critical
  nodeSelector: {}
  tolerations: []
  healthPort: 5557
  livenessProbe:
    initialDelaySeconds: 15
    periodSeconds: 15
    timeoutSeconds: 5
    successThreshold: 1
    failureThreshold: 6
  readinessProbe:
    initialDelaySeconds: 15
    periodSeconds: 15
    timeoutSeconds: 5
    successThreshold: 1
    failureThreshold: 6
  deploymentAnnotations: {}
  podAnnotations: {}
  env: []
  envFrom: []
  volumes: []
  volumeMounts: []
  networkPolicy:
    create: false
  additionalLabels: {}
  securityContext: {}
  ports: []
datadog-crds:
  crds:
    datadogMetrics: true
kube-state-metrics:
  rbac:
    create: true
  serviceAccount:
    create: true
    name:
  resources: {}
  nodeSelector:
    kubernetes.io/os: linux
providers:
  gke:
    autopilot: false
  eks:
    ec2:
      useHostnameFromFile: false
